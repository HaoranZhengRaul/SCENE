This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. 
[![CC BY-SA 4.0](https://licensebuttons.net/l/by-sa/4.0/88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)


# Demystifying the AI Black Box

## Evaluating Explainable AI Techniques Using Soft Counterfactuals


### Authors
- Haoran Zheng

### Advisors
- Advisor: Utku Pamuksuz, PhD



## Abstract
Explainable Artificial Intelligence (XAI) is essential for enhancing the transparency and accountability of AI models, especially in natural language processing (NLP) tasks. This paper introduces SCENE (Soft Counterfactual Evaluation for Natural language Explainability), a novel evaluation method that leverages large language models (LLMs) to generate Soft Counterfactual explanations in a zero-shot manner.  By focusing on token-based substitutions, SCENE creates contextually appropriate and semantically meaningful Soft Counterfactuals without extensive fine-tuning. SCENE adopts Validitysoft and Csoft metrics to evaluate the effectiveness of model-agnostic XAI methods in text classification tasks. Applied to CNN, RNN, and BERT architectures, SCENE provides valuable insights into the strengths and limitations of various XAI techniques.


**Keywords:** Explainable Artificial Intelligence, Natural Language Processing, Text Classification, Perturbation, Counterfactual Explanation, Soft Counterfactual Evaluation Metrics.




