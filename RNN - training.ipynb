{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NICuiHLpp1Jc",
    "outputId": "8c1d42de-2d64-4d8b-a606-1704304e547f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Content Sentiment\n",
      "0  synopsis : the president of a company wants to...  Negative\n",
      "1  \" take a number , fill out a form , and wait y...  Positive\n",
      "2  here 's a concept -- jean - claude van damme g...  Negative\n",
      "3  originally launched in 1978 , this popular fil...  Positive\n",
      "4  it shows that america remains ambivalent over ...  Positive\n",
      "                                                Content Sentiment\n",
      "366   susan granger 's review of \" osmosis jones \" (...  Positive\n",
      "1325  for a movie about disco - era excess , \" 54 \" ...  Positive\n",
      "133   kate ( jennifer aniston ) is having some probl...  Negative\n",
      "1419  i 'm not quite sure what to say about mars att...  Positive\n",
      "1258  saw an advanced screening of the movie sniper ...  Negative\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define a custom dataset\n",
    "class MovieReviewsDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        content = row['Content']\n",
    "        sentiment = row['Sentiment']\n",
    "        label = 1 if sentiment == 'Positive' else 0\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            content,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)  # Ensure the label is a long for CrossEntropyLoss\n",
    "        }\n",
    "\n",
    "# Load the dataset from CSV files\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "val_df = pd.read_csv('val_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "print(train_df.head())\n",
    "\n",
    "train_indices = train_df.sample(frac=1, random_state=200).index\n",
    "train_df = train_df.loc[train_indices]\n",
    "\n",
    "print(train_df.head())\n",
    "\n",
    "# Create data loaders\n",
    "max_len = 512\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = MovieReviewsDataset(train_df, tokenizer, max_len)\n",
    "val_dataset = MovieReviewsDataset(val_df, tokenizer, max_len)\n",
    "test_dataset = MovieReviewsDataset(test_df, tokenizer, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVl_1l5suxYR",
    "outputId": "7826942f-941a-444e-a82d-78882fcca116"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6735 accuracy 0.5881\n",
      "Train Confusion Matrix:\n",
      "[[437 363]\n",
      " [296 504]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6071 accuracy 0.7500\n",
      "Validation Confusion Matrix:\n",
      "[[90 10]\n",
      " [40 60]]\n",
      "Saved best model at epoch 1\n",
      "Epoch 2/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6081 accuracy 0.6850\n",
      "Train Confusion Matrix:\n",
      "[[558 242]\n",
      " [262 538]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5517 accuracy 0.7450\n",
      "Validation Confusion Matrix:\n",
      "[[88 12]\n",
      " [39 61]]\n",
      "Epoch 3/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5555 accuracy 0.7431\n",
      "Train Confusion Matrix:\n",
      "[[635 165]\n",
      " [246 554]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5850 accuracy 0.6800\n",
      "Validation Confusion Matrix:\n",
      "[[51 49]\n",
      " [15 85]]\n",
      "Epoch 4/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5384 accuracy 0.7619\n",
      "Train Confusion Matrix:\n",
      "[[607 193]\n",
      " [188 612]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5503 accuracy 0.7400\n",
      "Validation Confusion Matrix:\n",
      "[[83 17]\n",
      " [35 65]]\n",
      "Epoch 5/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5180 accuracy 0.7900\n",
      "Train Confusion Matrix:\n",
      "[[634 166]\n",
      " [170 630]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5754 accuracy 0.7250\n",
      "Validation Confusion Matrix:\n",
      "[[71 29]\n",
      " [26 74]]\n",
      "Epoch 6/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.4815 accuracy 0.8269\n",
      "Train Confusion Matrix:\n",
      "[[662 138]\n",
      " [139 661]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5337 accuracy 0.7650\n",
      "Validation Confusion Matrix:\n",
      "[[86 14]\n",
      " [33 67]]\n",
      "Saved best model at epoch 6\n",
      "Epoch 7/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.4992 accuracy 0.8069\n",
      "Train Confusion Matrix:\n",
      "[[644 156]\n",
      " [153 647]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5629 accuracy 0.7250\n",
      "Validation Confusion Matrix:\n",
      "[[89 11]\n",
      " [44 56]]\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 8/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.4556 accuracy 0.8569\n",
      "Train Confusion Matrix:\n",
      "[[690 110]\n",
      " [119 681]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5788 accuracy 0.7150\n",
      "Validation Confusion Matrix:\n",
      "[[73 27]\n",
      " [30 70]]\n",
      "Epoch 9/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.4310 accuracy 0.8856\n",
      "Train Confusion Matrix:\n",
      "[[705  95]\n",
      " [ 88 712]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5785 accuracy 0.7150\n",
      "Validation Confusion Matrix:\n",
      "[[76 24]\n",
      " [33 67]]\n",
      "Epoch 10/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.4011 accuracy 0.9187\n",
      "Train Confusion Matrix:\n",
      "[[732  68]\n",
      " [ 62 738]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5587 accuracy 0.7400\n",
      "Validation Confusion Matrix:\n",
      "[[77 23]\n",
      " [29 71]]\n",
      "Epoch 11/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.4779 accuracy 0.8337\n",
      "Train Confusion Matrix:\n",
      "[[728  72]\n",
      " [194 606]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5987 accuracy 0.6950\n",
      "Validation Confusion Matrix:\n",
      "[[60 40]\n",
      " [21 79]]\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 12/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.4750 accuracy 0.8387\n",
      "Train Confusion Matrix:\n",
      "[[690 110]\n",
      " [148 652]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5985 accuracy 0.6950\n",
      "Validation Confusion Matrix:\n",
      "[[71 29]\n",
      " [32 68]]\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 13/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3921 accuracy 0.9244\n",
      "Train Confusion Matrix:\n",
      "[[740  60]\n",
      " [ 61 739]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6007 accuracy 0.6800\n",
      "Validation Confusion Matrix:\n",
      "[[61 39]\n",
      " [25 75]]\n",
      "Epoch 14/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3675 accuracy 0.9525\n",
      "Train Confusion Matrix:\n",
      "[[765  35]\n",
      " [ 41 759]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5931 accuracy 0.6950\n",
      "Validation Confusion Matrix:\n",
      "[[74 26]\n",
      " [35 65]]\n",
      "Epoch 15/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3498 accuracy 0.9669\n",
      "Train Confusion Matrix:\n",
      "[[779  21]\n",
      " [ 32 768]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6439 accuracy 0.6450\n",
      "Validation Confusion Matrix:\n",
      "[[92  8]\n",
      " [63 37]]\n",
      "Epoch 16/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5084 accuracy 0.8019\n",
      "Train Confusion Matrix:\n",
      "[[724  76]\n",
      " [241 559]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6036 accuracy 0.6800\n",
      "Validation Confusion Matrix:\n",
      "[[65 35]\n",
      " [29 71]]\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 17/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3734 accuracy 0.9494\n",
      "Train Confusion Matrix:\n",
      "[[763  37]\n",
      " [ 44 756]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6037 accuracy 0.6750\n",
      "Validation Confusion Matrix:\n",
      "[[59 41]\n",
      " [24 76]]\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 18/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3512 accuracy 0.9669\n",
      "Train Confusion Matrix:\n",
      "[[773  27]\n",
      " [ 26 774]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5927 accuracy 0.7100\n",
      "Validation Confusion Matrix:\n",
      "[[71 29]\n",
      " [29 71]]\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 19/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3459 accuracy 0.9731\n",
      "Train Confusion Matrix:\n",
      "[[779  21]\n",
      " [ 22 778]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6203 accuracy 0.6800\n",
      "Validation Confusion Matrix:\n",
      "[[67 33]\n",
      " [31 69]]\n",
      "Epoch 20/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3396 accuracy 0.9769\n",
      "Train Confusion Matrix:\n",
      "[[783  17]\n",
      " [ 20 780]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6199 accuracy 0.6750\n",
      "Validation Confusion Matrix:\n",
      "[[69 31]\n",
      " [34 66]]\n",
      "Epoch 21/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3336 accuracy 0.9825\n",
      "Train Confusion Matrix:\n",
      "[[788  12]\n",
      " [ 16 784]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6104 accuracy 0.6900\n",
      "Validation Confusion Matrix:\n",
      "[[69 31]\n",
      " [31 69]]\n",
      "Epoch 22/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3318 accuracy 0.9825\n",
      "Train Confusion Matrix:\n",
      "[[789  11]\n",
      " [ 17 783]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6203 accuracy 0.6750\n",
      "Validation Confusion Matrix:\n",
      "[[67 33]\n",
      " [32 68]]\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 23/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3350 accuracy 0.9800\n",
      "Train Confusion Matrix:\n",
      "[[785  15]\n",
      " [ 17 783]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6222 accuracy 0.6750\n",
      "Validation Confusion Matrix:\n",
      "[[63 37]\n",
      " [28 72]]\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 24/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3309 accuracy 0.9838\n",
      "Train Confusion Matrix:\n",
      "[[788  12]\n",
      " [ 14 786]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6170 accuracy 0.6750\n",
      "Validation Confusion Matrix:\n",
      "[[71 29]\n",
      " [36 64]]\n",
      "Epoch 25/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3286 accuracy 0.9856\n",
      "Train Confusion Matrix:\n",
      "[[790  10]\n",
      " [ 13 787]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6255 accuracy 0.6750\n",
      "Validation Confusion Matrix:\n",
      "[[61 39]\n",
      " [26 74]]\n",
      "Epoch 26/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3279 accuracy 0.9856\n",
      "Train Confusion Matrix:\n",
      "[[790  10]\n",
      " [ 13 787]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6163 accuracy 0.6750\n",
      "Validation Confusion Matrix:\n",
      "[[71 29]\n",
      " [36 64]]\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 27/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3276 accuracy 0.9862\n",
      "Train Confusion Matrix:\n",
      "[[791   9]\n",
      " [ 13 787]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6222 accuracy 0.6750\n",
      "Validation Confusion Matrix:\n",
      "[[63 37]\n",
      " [28 72]]\n",
      "Epoch 28/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3273 accuracy 0.9862\n",
      "Train Confusion Matrix:\n",
      "[[791   9]\n",
      " [ 13 787]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6132 accuracy 0.7000\n",
      "Validation Confusion Matrix:\n",
      "[[68 32]\n",
      " [28 72]]\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 29/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3267 accuracy 0.9869\n",
      "Train Confusion Matrix:\n",
      "[[792   8]\n",
      " [ 13 787]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6151 accuracy 0.6950\n",
      "Validation Confusion Matrix:\n",
      "[[67 33]\n",
      " [28 72]]\n",
      "Epoch 30/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3266 accuracy 0.9869\n",
      "Train Confusion Matrix:\n",
      "[[792   8]\n",
      " [ 13 787]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6149 accuracy 0.6950\n",
      "Validation Confusion Matrix:\n",
      "[[67 33]\n",
      " [28 72]]\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 31/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3266 accuracy 0.9869\n",
      "Train Confusion Matrix:\n",
      "[[792   8]\n",
      " [ 13 787]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6116 accuracy 0.6950\n",
      "Validation Confusion Matrix:\n",
      "[[67 33]\n",
      " [28 72]]\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 32/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3265 accuracy 0.9869\n",
      "Train Confusion Matrix:\n",
      "[[792   8]\n",
      " [ 13 787]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6136 accuracy 0.6950\n",
      "Validation Confusion Matrix:\n",
      "[[67 33]\n",
      " [28 72]]\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 33/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3265 accuracy 0.9869\n",
      "Train Confusion Matrix:\n",
      "[[792   8]\n",
      " [ 13 787]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6145 accuracy 0.6950\n",
      "Validation Confusion Matrix:\n",
      "[[67 33]\n",
      " [28 72]]\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch 34/40\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3265 accuracy 0.9869\n",
      "Train Confusion Matrix:\n",
      "[[792   8]\n",
      " [ 13 787]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6140 accuracy 0.6900\n",
      "Validation Confusion Matrix:\n",
      "[[67 33]\n",
      " [29 71]]\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Test loss 0.5453 accuracy 0.7300\n",
      "Best Model Test Confusion Matrix:\n",
      "[[89 11]\n",
      " [43 57]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Epoch Model Test loss 0.5403 accuracy 0.7650\n",
      "Last Epoch Model Test Confusion Matrix:\n",
      "[[82 18]\n",
      " [29 71]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Define the RNN model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, n_layers, dropout_prob):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.LSTM(bert_model.config.hidden_size, hidden_dim, num_layers=n_layers, batch_first=True, dropout=dropout_prob, bidirectional=False)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.softmax = nn.Softmax(dim=1)  # Add a softmax activation\n",
    "\n",
    "    def forward(self, bert_embeddings):\n",
    "        packed_output, (hidden, cell) = self.rnn(bert_embeddings)\n",
    "        output = self.fc(self.dropout(hidden[-1]))\n",
    "        return self.softmax(output)  # Apply softmax activation\n",
    "\n",
    "# Instantiate the model\n",
    "hidden_dim = 128\n",
    "output_dim = 2  # Two outputs, one for each class\n",
    "n_layers = 1\n",
    "dropout_prob = 0.3\n",
    "\n",
    "model = RNNModel(hidden_dim, output_dim, n_layers, dropout_prob)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00033960197625562883)\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device, bert_model):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in tqdm(data_loader, desc=\"Training\", leave=False):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)  # Ensure labels are long for CrossEntropyLoss\n",
    "\n",
    "        # Get BERT embeddings\n",
    "        with torch.no_grad():\n",
    "            bert_outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            bert_embeddings = bert_outputs.last_hidden_state\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(bert_embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    accuracy = correct_predictions.double() / len(data_loader.dataset)\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    return accuracy, avg_loss, conf_matrix\n",
    "\n",
    "# Evaluation function\n",
    "def eval_model(model, data_loader, criterion, device, bert_model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)  # Ensure labels are long for CrossEntropyLoss\n",
    "\n",
    "            # Get BERT embeddings\n",
    "            bert_outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            bert_embeddings = bert_outputs.last_hidden_state\n",
    "\n",
    "            outputs = model(bert_embeddings)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    accuracy = correct_predictions.double() / len(data_loader.dataset)\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    return accuracy, avg_loss, conf_matrix\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_acc = 0.0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, train_acc, model):\n",
    "        if train_acc > self.best_acc:\n",
    "            self.best_acc = train_acc\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Training loop with early stopping\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "bert_model = bert_model.to(device)  # Move BERT model to device\n",
    "num_epochs = 40\n",
    "best_val_acc = 0.0  # Initialize the best validation accuracy to zero\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)  # Initialize early stopping\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss, train_conf_matrix = train_epoch(model, train_loader, criterion, optimizer, device, bert_model)\n",
    "    print(f'Train loss {train_loss:.4f} accuracy {train_acc:.4f}')\n",
    "    print('Train Confusion Matrix:')\n",
    "    print(train_conf_matrix)\n",
    "\n",
    "    val_acc, val_loss, val_conf_matrix = eval_model(model, val_loader, criterion, device, bert_model)\n",
    "    print(f'Val loss {val_loss:.4f} accuracy {val_acc:.4f}')\n",
    "    print('Validation Confusion Matrix:')\n",
    "    print(val_conf_matrix)\n",
    "\n",
    "    # Save the model if the validation accuracy is the best we've seen so far\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f'Saved best model at epoch {epoch + 1}')\n",
    "\n",
    "    # Check early stopping\n",
    "    early_stopping(train_acc, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Save the model at the last epoch\n",
    "torch.save(model.state_dict(), 'last_epoch_model.pth')\n",
    "\n",
    "# Load the best model before evaluating on the test set\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluate on test data using the best model\n",
    "test_acc_best, test_loss_best, test_conf_matrix_best = eval_model(model, test_loader, criterion, device, bert_model)\n",
    "print(f'Best Model Test loss {test_loss_best:.4f} accuracy {test_acc_best:.4f}')\n",
    "print('Best Model Test Confusion Matrix:')\n",
    "print(test_conf_matrix_best)\n",
    "\n",
    "# Load the model from the last epoch\n",
    "model.load_state_dict(torch.load('last_epoch_model.pth'))\n",
    "\n",
    "# Evaluate on test data using the last epoch model\n",
    "test_acc_last, test_loss_last, test_conf_matrix_last = eval_model(model, test_loader, criterion, device, bert_model)\n",
    "print(f'Last Epoch Model Test loss {test_loss_last:.4f} accuracy {test_acc_last:.4f}')\n",
    "print('Last Epoch Model Test Confusion Matrix:')\n",
    "print(test_conf_matrix_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QXRTdgwGt_PP",
    "outputId": "d08097c7-1b2d-462c-f111-31f5db383693",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \"That movie is terrific\"\n",
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model = RNNModel(hidden_dim, output_dim, n_layers, dropout_prob)\n",
    "model.load_state_dict(torch.load('last_epoch_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Inference function\n",
    "def predict(text, tokenizer, bert_model, model, device):\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bert_outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        bert_embeddings = bert_outputs.last_hidden_state\n",
    "\n",
    "        outputs = model(bert_embeddings)\n",
    "        _, prediction = torch.max(outputs, dim=1)\n",
    "\n",
    "    return prediction.item()\n",
    "\n",
    "# Perform inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "bert_model = bert_model.to(device)\n",
    "\n",
    "text = \"That movie is terrific\"\n",
    "prediction = predict(text, tokenizer, bert_model, model, device)\n",
    "\n",
    "# Map prediction to sentiment\n",
    "sentiment = \"Positive\" if prediction == 1 else \"Negative\"\n",
    "print(f'Text: \"{text}\"')\n",
    "print(f'Predicted Sentiment: {sentiment}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "Welcome To Colab",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
